---
title: "MVA_Final_Rutwik_Guntoorkar"
author: "Rutwik Guntoorkar"
date: "2023-05-01"
output: html_document
editor_options: 
  chunk_output_type: console
---

  
## Loading the Dataset
  
```{r}
library(readxl)
library(MVA)
library(HSAUR2)
library(SciViews)
library(scatterplot3d)
library(car)
library(lattice)
library(GGally)
library(ggplot2)
library(ggridges)
library(ggvis)
library(ggthemes)
library(cowplot)
library(gapminder)
library(gganimate)
library(dplyr)
library(tidyverse)
library(grid)
library(gridExtra)
library(RColorBrewer)
library(Hotelling)
library(stats)
library(biotools)
library(factoextra)
library(FactoMineR)
library(ggfortify)
library(psych)
library(corrplot)
library(devtools)
library(cluster)
library(magrittr)
library(NbClust)
library(MASS)
library(gvlma)
library(leaps)
library(relaimpo)
library(e1071)
library(pROC)
library(memisc)
library(ROCR)
library(klaR)
library(caret)
library(caTools)
library(ISLR)
mydata <- read_excel("/Users/rutwik/Desktop/RBS/Sem 2/Multivariate Analysis/Final_MVA_2023.xlsx")


attach(mydata)
```

### Tasks:

> 1. The age of abalone is determined by cutting the shell through the cone, staining it, and
counting the number of rings through a microscope -- a boring and time-consuming task.
You will build a regression model to determine the age of the Abalone from the other
attributes. How good is your model? Make sure your residual analysis shows no
patterns and is normally distributed. What attributes proved valuable in predicting the
age?
2. Once you have the model, use the rings column to determine the accuracy measure of
your model. Remember, just pick one measure of accuracy (MAPE would be my
recommendation)
3. Are you able to predict the gender from the other attributres? What is the accuracy using
logistic regression? What is the accuracy using LDA? What about the other measures of
accuracy?
4. Does dimension reduction techniques make your classification model better?

### Analysing the Data

```{r}
str(mydata)

mydata$age <- mydata$Rings + 1.5

summary(mydata)
```

```{r}
ggpairs(mydata, aes(colour = Gender, alpha = 0.8), title="Pairs plot for abalone dataset") + 
  theme_grey(base_size = 8)
```

> Observations:
The data have a strong correlation, which is the first thing to remark. The predictors appear to be very multicollinear with one. 'Diameter' and 'Length,' for instance, have a connection that is exceptionally high (around 97.8).
Similar to "Shucked_weight," "Viscera_weight," and "Shell_weight," "Whole_weight" also appears to have a strong correlation with other weight predictors.
 Second, compared to all other predictors, the distributions of the predictor "Sex" with factor level values of "female" and "male" are highly comparable.


```{r}

# Split the data into training and test sets

set.seed(123)
trainIndex <- createDataPartition(mydata$Rings, p = .8, 
                                  list = FALSE, 
                                  times = 1)
train_data <- mydata[trainIndex, ]
test_data <- mydata[-trainIndex, ]


# Fit a linear regression model to predict age using all other attributes
model <- lm(age ~ .-Rings, data = train_data)

# Evaluate the model on the test set
predictions <- predict(model, newdata = test_data)
library(Metrics)
rmse <- rmse(predictions, test_data$age)
mape <- mean(abs((test_data$age - predictions)/test_data$age)) * 100



cat("RMSE:",rmse)
cat("MAPE:",mape)

# Check the residuals for patterns and normality
plot(model, which = 1)  # Residuals vs. Fitted plot
plot(model, which = 2)  # Normal Q-Q plot
hist(model$residuals)   # Histogram for Residuals

# Determine which attributes are valuable in predicting age
summary(model)

```

> ### Observations:

* The p-values associated with most of the predictor variables are less than 0.05, indicating that these variables are statistically significant in predicting the age of the abalone. These variables are diameter, height, whole weight, shucked weight, viscera weight, and shell weight.

* The p-value for the Gender variable is greater than 0.05, indicating that it is not statistically significant in predicting the age of the abalone.

* The Adjusted R-squared value is 0.3855, indicating that the predictor variables explain 38.55% of the variation in the response variable, age.

* The F-statistic value is 178.8 with a p-value of < 2.2e-16, indicating that the model is significant.

* RMSE value is 2.291639

* MAPE value is 14.3003

* Histogram of the residuals in model shows normal distribution

* QQ plot shows that the data have more extreme values than would be expected


```{r}
# Convert gender column to binary
mydata$Gender <- ifelse(mydata$Gender == "M", 1, 0)

# Split the data into training and testing sets
set.seed(123)
train_size <- floor(0.7 * nrow(mydata))
train_data <- mydata[1:train_size, ]
test_data <- mydata[-(1:train_size), ]

# Build a logistic regression model
log_model <- glm(Gender ~ . - Gender, data = train_data, family = binomial)

# Check the model summary
summary(log_model)

# Make predictions on the test set
log_pred <- predict(log_model, newdata = test_data, type = "response")
log_pred <- ifelse(log_pred > 0.5, 1, 0)


# Calculate accuracy measures
table(log_pred, test_data$Gender)
acc <- sum(log_pred == test_data$Gender)/length(test_data$Gender)
acc

# Build an LDA model
lda_model <- lda(Gender ~ . - Gender, data = train_data)

# Check the model summary
summary(lda_model)

# Make predictions on the test set
lda_pred <- predict(lda_model, newdata = test_data)
lda_pred <- lda_pred$class

# Calculate accuracy measures
table(lda_pred, test_data$Gender)
acc <- sum(lda_pred == test_data$Gender)/length(test_data$Gender)
acc

#Plotting AUC plot for logistics regression.
roc <- roc(test_data$Gender, log_pred)
plot(roc, main = "ROC Curve", print.auc = TRUE, legacy.axes = TRUE)

```

>### Doing PCA to reduce dimensions in data set.

```{r}
mydata_pca <- prcomp(mydata[2:9],scale. = TRUE)

### Scree diagram
fviz_eig(mydata_pca, addlabels = TRUE)

mydata_pca
summary(mydata_pca)


mydata_pca <- as.data.frame(mydata_pca$x) 
mydata_pca <- mydata_pca[1:2]

mydata_pca$Gender <- mydata$Gender

# Split the data into training and testing sets
set.seed(123)
train_size_1 <- floor(0.7 * nrow(mydata_pca))
train_data_1 <- mydata_pca[1:train_size_1, ]
test_data_1 <- mydata_pca[-(1:train_size_1), ]

# Build a logistic regression model
log_model_1 <- glm(Gender ~ . - Gender, data = train_data_1, family = binomial)

# Check the model summary
summary(log_model_1)

# Make predictions on the test set
log_pred_1 <- predict(log_model_1, newdata = test_data_1, type = "response")
log_pred_1 <- ifelse(log_pred_1 > 0.5, 1, 0)


# Calculate accuracy measures
table(log_pred_1, test_data_1$Gender)
acc_1 <- sum(log_pred_1 == test_data_1$Gender)/length(test_data_1$Gender)
acc_1

#Plotting AUC plot for logistics regression.
roc1 <- roc(test_data_1$Gender, log_pred_1)
plot(roc1, main = "ROC Curve", print.auc = TRUE, legacy.axes = TRUE)
```

> ### Observations:
* After performing logistic regression on PCs, the result was not improved as AUC comes to be 50.9%

### Checking wheter the results are better withv Exploratory Factor Analysis (EFA)

```{r}
fa.parallel(mydata[2:9])

fit.pc <- principal(mydata[2:9], nfactors=2, rotate="varimax")
fa.diagram(fit.pc)

efa_mydata <- as.data.frame(fit.pc$scores)
efa_mydata$Gender <- mydata$Gender

# Split the data into training and testing sets
set.seed(123)
train_size_2 <- floor(0.8 * nrow(efa_mydata))
train_data_2 <- efa_mydata[1:train_size_2, ]
test_data_2 <- efa_mydata[-(1:train_size_2), ]

# Build a logistic regression model
log_model_2 <- glm(Gender ~ . - Gender, data = train_data_2, family = binomial)

# Check the model summary
summary(log_model_2)

# Make predictions on the test set
log_pred_2 <- predict(log_model_2, newdata = test_data_2, type = "response")
log_pred_2 <- ifelse(log_pred_2 > 0.5, 1, 0)


# Calculate accuracy measures
table(log_pred_2, test_data_2$Gender)
acc_2 <- sum(log_pred_2 == test_data_2$Gender)/length(test_data_2$Gender)
acc_2

#Plotting AUC plot for logistics regression.
roc2 <- roc(test_data_2$Gender, log_pred_2)
plot(roc2, main = "ROC Curve", print.auc = TRUE, legacy.axes = TRUE)
```

 
> ### Observations:
* Even after performing logistic regression on Factors, the result was not improved as AUC comes to be 50.1% only so we can conclude that in this case, dimension reduction techniques did not make classification model better.
